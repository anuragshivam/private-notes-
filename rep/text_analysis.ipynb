{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd     \n",
    "import re\n",
    "import numpy as np \n",
    "from bs4 import BeautifulSoup \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnlzer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading our data \n",
    "train = pd.read_csv(\"labeledTrainData.tsv\" , header = 0 ,  \\\n",
    "\tdelimiter = '\\t' , quoting  = 3)\n",
    "test = pd.read_csv('testData.tsv' , header = 0 , delimiter = '\\t' , quoting = 3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the function takes a review in the form of a string , and after doing the processing outputs a string.\n",
    "##### after that we form a list of reviews and then pass each review to the function using a for loop.  \n",
    "##### in the last the list has all the reviews as individual elements of the list and is now ready to be fed into the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_string_to_list_clean_string( raw_train_review ):\n",
    "\tremove_html = BeautifulSoup( raw_train_review ).text\n",
    "\tremove_punch = re.sub('[^A-Za-z ]' , \"\" , remove_html)\n",
    "\ttoken = remove_punch.lower().split()\n",
    "\tsrm_token = [wnlzer.lemmatize(i) for i in token if not i in set(stopwords.words('english'))]\n",
    "\tclean_text = \" \".join(srm_token)\n",
    "\treturn(clean_text)\n",
    "\n",
    "ready_train_list = []\n",
    "length  = len(train['review'])\n",
    "for i in range(0 , length):\n",
    "# the if loop is to track the progress only. It has nothing to do with the analysis\n",
    "\tif (i%100 == 0):\n",
    "\t\tprint \"doing  %d of  %d of training data set\" % (i+1 , length)\n",
    "\ta = raw_string_to_list_clean_string(train['review'][i])\n",
    "\tready_train_list.append(a)\n",
    "    \n",
    "ready_test_list = []\n",
    "for i in range(0 , test_length):\n",
    "\ta = raw_string_to_list_clean_string(test['review'][i])\n",
    "\ttest_text.append(a)\n",
    "# if loop is to check for updates \n",
    "\tif( i%100 == 0):\n",
    "\t\tprint \"doing    %d out of  %d  of test data \" % (i+1 , test_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initially I was using the count_vectorizer but after some reading i figured out that tf-idf is better for sparse metrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer = \"word\" , tokenizer = None , preprocessor = None , \\\n",
    "\tstop_words = None , max_features = 20000)\n",
    "train_vectorizer = vectorizer.fit_transform(ready_train_list)\n",
    "test_vectorizer  = vectorizer.transform(ready_test_list)\n",
    "# i also used the hashing_vectorizer but the score was not changed much so i reverted back to tfidf vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### my first obvious choice was logistic regression but with SGD i could use both logistic and SVM with 'loss' parameter and by using GridSearchCV .     Both logistic and SVM gave the same 78.98% . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(alpha = 0.01)\n",
    "clf.fit(train_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(test_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_dataframe = pd.DataFrame( data = { 'id' : test['id'] , 'sentiment' : prediction })\n",
    "final_dataframe.to_csv( \"improving_on_kaggle_part01.csv\" , index = False ,quoting = 3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some additional points , Apart from Hashing i also tried Truncated SVD but the Progress was too less. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
